<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>STAT 771: My notes</title>
  <meta name="description" content="This is my collection of notes for the STAT 771 class taught at UW-Madison.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="STAT 771: My notes" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is my collection of notes for the STAT 771 class taught at UW-Madison." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="STAT 771: My notes" />
  
  <meta name="twitter:description" content="This is my collection of notes for the STAT 771 class taught at UW-Madison." />
  

<meta name="author" content="Ralph Møller Trane">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="lecture-notes.html">
<link rel="next" href="homework-assignments.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Intro</a></li>
<li class="chapter" data-level="2" data-path="lecture-notes.html"><a href="lecture-notes.html"><i class="fa fa-check"></i><b>2</b> Lecture Notes</a><ul>
<li class="chapter" data-level="2.1" data-path="lecture-notes.html"><a href="lecture-notes.html#quick-walk-through-of-the-syllabus"><i class="fa fa-check"></i><b>2.1</b> Quick walk through of the syllabus</a></li>
<li class="chapter" data-level="2.2" data-path="lecture-notes.html"><a href="lecture-notes.html#lecture-1-96"><i class="fa fa-check"></i><b>2.2</b> Lecture 1: 9/6</a><ul>
<li class="chapter" data-level="2.2.1" data-path="lecture-notes.html"><a href="lecture-notes.html#positional-numeral-system"><i class="fa fa-check"></i><b>2.2.1</b> Positional numeral system</a></li>
<li class="chapter" data-level="2.2.2" data-path="lecture-notes.html"><a href="lecture-notes.html#floating-point-format"><i class="fa fa-check"></i><b>2.2.2</b> Floating Point Format</a></li>
<li class="chapter" data-level="2.2.3" data-path="lecture-notes.html"><a href="lecture-notes.html#ieee-standards"><i class="fa fa-check"></i><b>2.2.3</b> IEEE Standards</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="part-lecture-2-911.html"><a href="part-lecture-2-911.html"><i class="fa fa-check"></i><b>3</b> (PART*) Lecture 2: 9/11</a><ul>
<li class="chapter" data-level="3.0.1" data-path="part-lecture-2-911.html"><a href="part-lecture-2-911.html#ieee-standards-cont."><i class="fa fa-check"></i><b>3.0.1</b> IEEE Standards (cont.)</a></li>
<li class="chapter" data-level="3.0.2" data-path="part-lecture-2-911.html"><a href="part-lecture-2-911.html#errors"><i class="fa fa-check"></i><b>3.0.2</b> Errors</a></li>
<li class="chapter" data-level="3.1" data-path="part-lecture-2-911.html"><a href="part-lecture-2-911.html#lecture-3-913"><i class="fa fa-check"></i><b>3.1</b> Lecture 3: 9/13</a><ul>
<li class="chapter" data-level="3.1.1" data-path="part-lecture-2-911.html"><a href="part-lecture-2-911.html#square-linear-systems"><i class="fa fa-check"></i><b>3.1.1</b> Square Linear Systems</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="part-lecture-2-911.html"><a href="part-lecture-2-911.html#orthogonalization"><i class="fa fa-check"></i><b>3.2</b> Orthogonalization</a><ul>
<li class="chapter" data-level="3.2.1" data-path="part-lecture-2-911.html"><a href="part-lecture-2-911.html#motivating-problems"><i class="fa fa-check"></i><b>3.2.1</b> Motivating problems</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="part-lecture-2-911.html"><a href="part-lecture-2-911.html#lecture-4-918"><i class="fa fa-check"></i><b>3.3</b> Lecture 4: 9/18</a><ul>
<li class="chapter" data-level="3.3.1" data-path="part-lecture-2-911.html"><a href="part-lecture-2-911.html#qr-decomposition"><i class="fa fa-check"></i><b>3.3.1</b> QR Decomposition</a></li>
<li class="chapter" data-level="3.3.2" data-path="part-lecture-2-911.html"><a href="part-lecture-2-911.html#existence-of-qr-decomposition."><i class="fa fa-check"></i><b>3.3.2</b> Existence of QR-decomposition.</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="part-lecture-2-911.html"><a href="part-lecture-2-911.html#lecture-5-920"><i class="fa fa-check"></i><b>3.4</b> Lecture 5: 9/20</a><ul>
<li class="chapter" data-level="3.4.1" data-path="part-lecture-2-911.html"><a href="part-lecture-2-911.html#householder"><i class="fa fa-check"></i><b>3.4.1</b> Householder</a></li>
<li class="chapter" data-level="3.4.2" data-path="part-lecture-2-911.html"><a href="part-lecture-2-911.html#givens-rotations"><i class="fa fa-check"></i><b>3.4.2</b> Givens Rotations</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="homework-assignments.html"><a href="homework-assignments.html"><i class="fa fa-check"></i><b>4</b> Homework Assignments</a><ul>
<li class="chapter" data-level="4.1" data-path="homework-assignments.html"><a href="homework-assignments.html#homework-1"><i class="fa fa-check"></i><b>4.1</b> Homework 1</a><ul>
<li class="chapter" data-level="4.1.1" data-path="homework-assignments.html"><a href="homework-assignments.html#theoretical-problems"><i class="fa fa-check"></i><b>4.1.1</b> Theoretical Problems</a></li>
<li class="chapter" data-level="4.1.2" data-path="homework-assignments.html"><a href="homework-assignments.html#implementation-problems"><i class="fa fa-check"></i><b>4.1.2</b> Implementation problems</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="homework-assignments.html"><a href="homework-assignments.html#homework-2"><i class="fa fa-check"></i><b>4.2</b> Homework 2</a><ul>
<li class="chapter" data-level="4.2.1" data-path="homework-assignments.html"><a href="homework-assignments.html#theoretical-problems-1"><i class="fa fa-check"></i><b>4.2.1</b> Theoretical problems</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="homework-assignments.html"><a href="homework-assignments.html#homework-3"><i class="fa fa-check"></i><b>4.3</b> Homework 3</a><ul>
<li class="chapter" data-level="4.3.1" data-path="homework-assignments.html"><a href="homework-assignments.html#theoretical-problems-2"><i class="fa fa-check"></i><b>4.3.1</b> Theoretical problems</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="homework-assignments.html"><a href="homework-assignments.html#homework-4"><i class="fa fa-check"></i><b>4.4</b> Homework 4</a></li>
<li class="chapter" data-level="4.5" data-path="homework-assignments.html"><a href="homework-assignments.html#homework-5"><i class="fa fa-check"></i><b>4.5</b> Homework 5</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">STAT 771: My notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="part-lecture-2-911" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> (PART*) Lecture 2: 9/11</h1>
<div id="ieee-standards-cont." class="section level3">
<h3><span class="header-section-number">3.0.1</span> IEEE Standards (cont.)</h3>
<div id="the-32-bit-standard-single-precision" class="section level4">
<h4><span class="header-section-number">3.0.1.1</span> The 32 bit standard (single precision)</h4>
<p>The 32 bits of storage are used in the following way, when following the 32 bit standard:</p>
<ul>
<li>1 bit for the sign
<ul>
<li>0 = positive</li>
<li>1 = negative</li>
</ul></li>
<li>8 bits for the exponent
<ul>
<li>00000000 is reserved for 0</li>
<li>11111111 is reserved for <span class="math inline">\(\infty\)</span></li>
<li>exponents left: <span class="math inline">\(2^8 - 2 = 254\)</span></li>
<li>the 32 bit standard dictates that the used exponents are <span class="math inline">\(-126,...,127\)</span>.
<ul>
<li><strong>Note</strong>: <span class="math inline">\(0\)</span> is also included in this list of the 254 exponents. This is because the <span class="math inline">\(00000000\)</span> representation is reserved for integers, while <span class="math inline">\(01111111\)</span> (I think this is the representation for <span class="math inline">\(0\)</span> here…) is used with non-integers.</li>
</ul></li>
</ul></li>
<li>24 bit for the significand.
<ul>
<li>23 are actually stored – we always work with normalized FP numbers, i.e. <span class="math inline">\(\beta_0 = 1\)</span>.</li>
</ul></li>
</ul>
<p><strong>Question:</strong> What are smallest and largest positive numbers that can be represented in the 32 bit standard?</p>
<p><strong>Answer:</strong> Smallest non-normalized number would be the one with the smallest possible exponent, and all digits of the significand are 0 except the very last one. So, the smallest non-normalized FP number in the 32 bit standard would be</p>
<p><span class="math display">\[
\left(0 + 0\cdot 2^{-1} + ... + 0\cdot 2^{-22} + 1\cdot 2^{-23}\right)\cdot 2^{-126} = 2^{-149} \approx 1.40\cdot 10^{-45}
\]</span></p>
<p>The smallest normalized number is the one with all digits <span class="math inline">\(0\)</span> (except for the leading digit, of course, which has to be <span class="math inline">\(1\)</span> for it to be normalized), and <span class="math inline">\(e = -126\)</span>. So the smallest normalized FP number:</p>
<p><span class="math display">\[
\left(1 + 0\cdot 2^{-1} + ... + 0\cdot 2^{-23}\right)\cdot 2^{-126} = 2^{-126} \approx 1.18\cdot 10^{-38}
\]</span> Finally, the largest (finite) FP number in the 32 bit standard is the one where the exponent is as large as possible (<span class="math inline">\(e = 127\)</span>), and all digits are <span class="math inline">\(1\)</span>. So</p>
<p><span class="math display">\[
\left(1 + 1\cdot 2^{-1} + ... + 1\cdot 2^{-126}\right)\cdot 2^{127} = 3.40\cdot 10^{38}
\]</span></p>
</div>
<div id="the-64-bit-standard-double-precision" class="section level4">
<h4><span class="header-section-number">3.0.1.2</span> The 64 bit standard (double precision)</h4>
<p>The 64 bits of storage are used in the following way, when following the 64 bit standard:</p>
<ul>
<li>1 bit for the sign
<ul>
<li>0 = positive</li>
<li>1 = negative</li>
</ul></li>
<li>11 bits for the exponent
<ul>
<li>00000000 is reserved for 0</li>
<li>11111111 is reserved for <span class="math inline">\(\infty\)</span></li>
<li>exponents left: <span class="math inline">\(2^11 - 2 = 2046\)</span></li>
<li>the 64 bit standard dictates that the used exponents are <span class="math inline">\(-1024,...,1023\)</span>.
<ul>
<li><strong>Note</strong>: <span class="math inline">\(0\)</span> is also included in this list of the 254 exponents. This is because the <span class="math inline">\(00000000\)</span> representation is reserved for integers, while <span class="math inline">\(01111111\)</span> (I think this is the representation for <span class="math inline">\(0\)</span> here…) is used with non-integers.</li>
</ul></li>
</ul></li>
<li>53 bit for the significand.
<ul>
<li>52 are actually stored – we always work with normalized FP numbers, i.e. <span class="math inline">\(\beta_0 = 1\)</span>.</li>
</ul></li>
</ul>
</div>
</div>
<div id="errors" class="section level3">
<h3><span class="header-section-number">3.0.2</span> Errors</h3>
<div id="units-in-the-last-place-ulp" class="section level4">
<h4><span class="header-section-number">3.0.2.1</span> Units in the Last Place (ULP)</h4>
</div>
<div id="absolute-and-relative-error" class="section level4">
<h4><span class="header-section-number">3.0.2.2</span> Absolute and Relative Error</h4>
<p>Let <span class="math inline">\(fl: \mathbb{R}_{\geq 0} \rightarrow \mathcal{S}\)</span> be a function that takes a real value and return a FP number. Then we define the absolute and relative error as follows:</p>

<div class="definition">
<p><span id="def:unnamed-chunk-5" class="definition"><strong>Definition 3.1  </strong></span>Let <span class="math inline">\(z \in \mathbb{R}_{\geq 0}\)</span>. The <em>absolute error</em> is defined as</p>
<p><span class="math display">\[
\left | fl(z) - z \right | .
\]</span></p>
<p>The <em>relative error</em> is defined as</p>
<span class="math display">\[
\left | \frac{fl(z)-z}{z} \right |
\]</span>
</div>


<div class="lemma">
<span id="lem:lem1" class="lemma"><strong>Lemma 3.1  </strong></span>If <span class="math inline">\(z\)</span> has exponent <span class="math inline">\(e\)</span>, then the maximum absolute error is <span class="math inline">\(\frac{\beta^{e-p+1}}{2}\)</span>.
</div>


<div class="proof">
 <span class="proof"><em>Proof. </em></span> 
</div>


<div class="lemma">
<span id="lem:unnamed-chunk-7" class="lemma"><strong>Lemma 3.2  </strong></span>If <span class="math inline">\(z\)</span> has exponent <span class="math inline">\(e\)</span>, then the maximum relative error is <span class="math inline">\(\frac{\beta^{1-p}}{2}\)</span>.
</div>


<div class="proof">
<p> <span class="proof"><em>Proof. </em></span> If <span class="math inline">\(z\)</span> has exponent <span class="math inline">\(e\)</span>, then <span class="math inline">\(\beta^{e}\leq z\)</span>. Using this with <a href="part-lecture-2-911.html#lem:lem1">3.1</a>, we get that</p>
<span class="math display">\[
\left | \frac{fl(z)-z}{z} \right | \leq \frac{\beta^{e-p+1}}{2\beta^e} = \frac{\beta^{1-p}}{2}.
\]</span>
</div>

<p><strong>Note:</strong> the upper bound of the relative error is called the <em>machine epsilon</em>. This can be obtained in Julia using the function <code>eps</code>.</p>
</div>
<div id="the-fundamental-axiom" class="section level4">
<h4><span class="header-section-number">3.0.2.3</span> The Fundamental Axiom</h4>
<p>… is that for any of the four arithmetic operations (<span class="math inline">\(+, -, \cdot, /\)</span>), we have the following error bound:</p>
<p><span class="math display">\[
fl(x \text{op} y) = (x \text{op} y)(1+\delta),
\]</span></p>
<p>with <span class="math inline">\(|\delta| \leq u\)</span>, where <span class="math inline">\(u\)</span> is commonly <span class="math inline">\(2\cdot \epsilon\)</span>. (<strong>NOTE: NEED TO CLARIFY IF THE ABOVE IS CORRECT!</strong>)</p>
<p>**Example:* Matrix storage. Let <span class="math inline">\(A \in \mathbb{R}^{m\times n}\)</span>. Then:</p>
<p><span class="math display">\[
\left| fl(A) - A \right | \leq u \left | A \right |
\]</span></p>
<p><strong>Example:</strong> Dot product. Let <span class="math inline">\(x,y \in \mathbb{R}^{n}\)</span>. Recall that the dot product of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> is definted as <span class="math inline">\(x&#39;y = \sum_{i=1}^{n} x_i \cdot y_i\)</span>. This can be calculated in the following way:</p>
<div class="sourceCode"><pre class="sourceCode julia"><code class="sourceCode julia">fl = <span class="kw">function</span>(x,y)
  <span class="co"># Get length of x</span>
  n = length(x)
  <span class="co"># Check that length of y is equal to length of x. If not, throw error.</span>
  <span class="kw">if</span>(length(y) != n)
    <span class="kw">return</span> <span class="st">&quot;ERROR: y does not have same dimension as x&quot;</span>
  <span class="kw">end</span>
  
  <span class="co"># s will be the result of the dot product calculation</span>
  s = <span class="fl">0</span>
  
  <span class="kw">for</span> i = <span class="fl">1</span>:n
    s += x[i]*y[i]
  <span class="kw">end</span>
  
  <span class="kw">return</span>(s)
  
<span class="kw">end</span></code></pre></div>
<p>Next we want to prove the following lemma:</p>

<div class="lemma">
<p><span id="lem:unnamed-chunk-10" class="lemma"><strong>Lemma 3.3  </strong></span>Let <span class="math inline">\(x,y \in \mathbb{R}^n\)</span>, and <span class="math inline">\(n\cdot u \leq 0.01\)</span>. Then</p>
<span class="math display">\[
\left | fl(x&#39;y) - x&#39;y \right | \leq 1.01 \cdot n\cdot u \cdot \left|x\right|&#39;\left|y\right|
\]</span>
</div>

</div>
</div>
<div id="lecture-3-913" class="section level2">
<h2><span class="header-section-number">3.1</span> Lecture 3: 9/13</h2>
<p>To prove the lemma above, we will need another lemma…</p>

<div class="lemma">
<p><span id="lem:lemForProof" class="lemma"><strong>Lemma 3.4  </strong></span>If <span class="math inline">\(|\delta_i| \leq u, \forall i=1,\ldots,n\)</span> s.t. <span class="math inline">\(n\cdot u &lt; 2\)</span>. Let <span class="math inline">\(1 + \eta = \prod_{i=1}^{n}(1 + \delta_i)\)</span>. Then</p>
<span class="math display">\[ 
|\eta | \leq \frac{n\cdot u}{1-\tfrac{n\cdot u}{2}}
\]</span>
</div>


<div class="proof">
<p> <span class="proof"><em>Proof. </em></span> Using the definition of <span class="math inline">\(\nu\)</span>, we can rewrite it to get</p>
<p><span class="math display">\[
| \eta | = \left | \prod_{i=1}^n (1 + \delta_i) - 1 \right |. 
\]</span></p>
<p>By induction, we will show that the expression above is less than or equal to <span class="math inline">\((1 + u)^n - 1\)</span>. [TO BE COMPLETED!]</p>
<p>Since <span class="math inline">\(1+u \leq e^{u}\)</span> for all <span class="math inline">\(u \in {\mathbb{R}}\)</span>, we have that</p>
<span class="math display">\[\begin{align*}
  | \eta | &amp;\leq e^{n\cdot u} - 1 \\
          &amp;\leq n\cdot u + \frac{(n\cdot u)^2}{2!} + \frac{(n\cdot u)^3}{3!} + \ldots \text{(used the Taylor expansion)}\\
          &amp;\leq n\cdot u + \frac{(n\cdot u)^2}{2^1} + \frac{(n\cdot u)^3}{2^2} + \frac{(n\cdot u)^4}{2^3} + \ldots (\text{used that } x! &gt; 2^{x-1} \text{ for } x &gt; 1) \\
          &amp;= \sum_{k=0}^{\infty} n\cdot u \left(\frac{n\cdot u}{2}\right)^k \text{\small (identify this as a geometric series with } r = \tfrac{n\cdot u}{2} \text{, \small which is less than 1 by assumption)} \\
          &amp;= \frac{n\cdot u}{1-\tfrac{n\cdot u}{2}},
\end{align*}\]</span>
which is exactly what we wanted.
</div>

<p>With this in hand, we will prove the previously stated lemma.</p>

<div class="proof">
<p> <span class="proof"><em>Proof. </em></span> Let <span class="math inline">\(s_p\)</span> denote the value of <span class="math inline">\(s\)</span> after the <span class="math inline">\(p\)</span>’th iteration of the algorithm described above. Then, since we’re assuming the Fundamental Axiom, we have that <span class="math inline">\(s_1 = fl(x_1y_y) = x_1 y_1 (1 + \delta_1)\)</span>, where <span class="math inline">\(|\delta_1| \leq u\)</span>. We can similarly find <span class="math inline">\(s_p\)</span> as</p>
<span class="math display">\[\begin{align*}
s_p &amp;= fl(s_{p-1} + fl(x_p y_p)) \\
    &amp;= (s_{p-1} + fl(x_p y_p))(1 + \epsilon_p) (\text{where } |\epsilon_p| \leq u) \\
    &amp;= (s_{p-1} + x_py_p(1 + \delta_p))(1 + \epsilon_p) (\text{where } |\delta_p| \leq u).
\end{align*}\]</span>
<p>Let <span class="math inline">\(\epsilon_1 = 0\)</span>. <span class="math inline">\(s_p\)</span> is a recursive formula, and can be rewritten as follows:</p>
<p><span class="math display">\[
s_p = \sum_{i=1}^p x_iy_i (1 + \delta_i)\prod_{j=1}^p (1 + \epsilon_j).
\]</span></p>
<p>So,</p>
<span class="math display">\[\begin{align*}
  | s_n - x^\prime y |  &amp;= \left | \sum_{i=1}^n (x_i y_i)(1 + \delta_i)\prod_{j=1}^p (1 + \epsilon_j) - \sum_{i=1}^{n}x_iy_i\right | \\
                        &amp;= \left | \sum_{i=1}^n (x_i y_i)\left((1 + \delta_i)\prod_{j=1}^p (1 + \epsilon_j) - 1 \right) \right | \\
                        &amp;\leq \sum_{i=1}^n \left |x_i y_i \right |\left | (1 + \delta_i)\prod_{j=1}^p (1 + \epsilon_j) - 1 \right| .
\end{align*}\]</span>
<p>We now use <a href="part-lecture-2-911.html#lem:lemForProof">3.4</a> to get:</p>
<span class="math display">\[\begin{align*}
\sum_{i=1}^n \left |x_i y_i \right |\left | (1 + \delta_i)\prod_{j=1}^p (1 + \epsilon_j) - 1 \right| &amp;\leq  \frac{nu}{1-\tfrac{nu}{2}} \sum_{i=1}^n \left |x_i y_i \right | \\
&amp;\leq \frac{nu}{0.995} \sum_{i=1}^n |x_i| |y_i | \\
&amp;\leq 1.01 \cdot nu \cdot |x|^\prime |y|
\end{align*}\]</span>
</div>

<div id="square-linear-systems" class="section level3">
<h3><span class="header-section-number">3.1.1</span> Square Linear Systems</h3>
<p>In the following, let <span class="math inline">\(A \in {\mathbb{R}}^{n \times m}\)</span> be an invertible matrix, and assume <span class="math inline">\(Ax = b\)</span> for a <span class="math inline">\(b \neq 0\)</span>. This implies that <span class="math inline">\(x = A^{-1}b\)</span>.</p>

<div class="theorem">
<p><span id="thm:unnamed-chunk-13" class="theorem"><strong>Theorem 3.1  </strong></span>Let <span class="math inline">\(\kappa_\infty = {\left \vert \left \vert A \right \vert \right \vert}_\infty {\left \vert \left \vert A^{-1} \right \vert \right \vert}_\infty\)</span>. Assume we can store <span class="math inline">\(A\)</span> with precision <span class="math inline">\(E\)</span> (i.e. as <span class="math inline">\(A+E\)</span>), where <span class="math inline">\({\left \vert \left \vert E \right \vert \right \vert}_\infty \leq u {\left \vert \left \vert A \right \vert \right \vert}_\infty\)</span>, and <span class="math inline">\(b\)</span> with precision <span class="math inline">\(e\)</span> (i.e. as <span class="math inline">\(b+e\)</span>), where <span class="math inline">\({\left \vert \left \vert e \right \vert \right \vert}_\infty \leq u {\left \vert \left \vert b \right \vert \right \vert}_\infty\)</span>.</p>
<p>If <span class="math inline">\({\left \vert \left \vert A+E \right \vert \right \vert}\hat{x} = b+e\)</span> and <span class="math inline">\(u\cdot \kappa_\infty &lt; 1\)</span>, then</p>
<span class="math display">\[
  \frac{{\left \vert \left \vert x-\hat{x} \right \vert \right \vert}_\infty}{{\left \vert \left \vert x \right \vert \right \vert}} \leq \frac{2\cdot u \cdot \kappa_\infty}{1-u\cdot \kappa_\infty}
\]</span>
</div>


<div class="lemma">
<p><span id="lem:proofHW" class="lemma"><strong>Lemma 3.5  </strong></span>Let <span class="math inline">\(I\in {\mathbb{R}}^{n \times n}\)</span> be the identity matrix, and <span class="math inline">\(F \in {\mathbb{R}}^{n\times n}\)</span> s.t. <span class="math inline">\({\left \vert \left \vert F \right \vert \right \vert}_p &lt; 1\)</span> for some <span class="math inline">\(p \in [1,\infty]\)</span>. Then <span class="math inline">\(I-F\)</span> is invertible, and</p>
<span class="math display">\[
  {\left \vert \left \vert (I-F)^{-1} \right \vert \right \vert}_p \leq \frac{1}{1-{\left \vert \left \vert F \right \vert \right \vert}_p}
\]</span>
</div>


<div class="proof">
 <span class="proof"><em>Proof. </em></span> <strong>HOMEWORK</strong>
</div>


<div class="lemma">
<p><span id="lem:unnamed-chunk-15" class="lemma"><strong>Lemma 3.6  </strong></span>Suppose <span class="math inline">\(\exists \epsilon &gt; 0\)</span> s.t. <span class="math inline">\({\left \vert \left \vert \Delta A \right \vert \right \vert} \leq \epsilon {\left \vert \left \vert A \right \vert \right \vert}\)</span> and <span class="math inline">\({\left \vert \left \vert \Delta b \right \vert \right \vert} \leq \epsilon {\left \vert \left \vert b \right \vert \right \vert}\)</span>, and <span class="math inline">\(y\)</span> s.t. <span class="math inline">\((A+\Delta A)y = b+\Delta b\)</span>.</p>
If <span class="math inline">\(\epsilon {\left \vert \left \vert A \right \vert \right \vert}{\left \vert \left \vert A^{-1} \right \vert \right \vert} = r &lt; 1\)</span>, then <span class="math inline">\(A+\Delta A\)</span> is invertible and <span class="math display">\[\frac{{\left \vert \left \vert y \right \vert \right \vert}}{{\left \vert \left \vert x \right \vert \right \vert}} \leq \frac{1+r}{1-r}.\]</span>
</div>


<div class="proof">
<p> <span class="proof"><em>Proof. </em></span> Note that <span class="math inline">\(A+\Delta A = A\left (I + A^{-1}\Delta A\right ) = A\left (I - \left(- A^{-1}\Delta A\right)\right)\)</span>. Since <span class="math inline">\({\left \vert \left \vert -A^{-1}\Delta A \right \vert \right \vert} = {\left \vert \left \vert A^{-1}\Delta A \right \vert \right \vert} \leq \epsilon {\left \vert \left \vert A^{-1} \right \vert \right \vert}\cdot {\left \vert \left \vert A \right \vert \right \vert} &lt; 1\)</span> (by assumptions), Lemma <a href="part-lecture-2-911.html#lem:proofHW">3.5</a> gives us that <span class="math inline">\(I + A^{-1}\Delta A\)</span> is invertible. Since <span class="math inline">\(A\)</span> is also invertible (again, by assumption), <span class="math inline">\(A+\Delta A\)</span> is invertible (product of two invertible matrices is invertible).</p>
<p>Performing some linear algebra:</p>
<span class="math display">\[\begin{align*}
  (A + \Delta A) &amp;=  b + \Delta b \Leftrightarrow \\
  A(I + A^{-1} \Delta A) y &amp;= b + \Delta b \Leftrightarrow \\
  (I + A^{-1} \Delta A) y &amp;= A^{-1}b + A^{-1}\Delta b \Leftrightarrow \\
  y &amp;= (I + A^{-1} \Delta A)^{-1} A^{-1}b + A^{-1}\Delta b.
\end{align*}\]</span>
<p>Remember that <span class="math inline">\(A^{-1}b = x\)</span>. From the definition of <span class="math inline">\(r\)</span> we have that <span class="math inline">\({\left \vert \left \vert A^{-1} \right \vert \right \vert} = \frac{r}{{\left \vert \left \vert A \right \vert \right \vert}}\)</span>. These two identities with the assumption that <span class="math inline">\({\left \vert \left \vert \Delta b \right \vert \right \vert} \leq \epsilon b\)</span> gives us</p>
<p><span class="math display">\[
\begin{aligned}
  {\left \vert \left \vert y \right \vert \right \vert} &amp;\leq {\left \vert \left \vert (I + A^{-1}\Delta A)^{-1} \right \vert \right \vert} \left( {\left \vert \left \vert x \right \vert \right \vert} + {\left \vert \left \vert A^{-1}\Delta b \right \vert \right \vert}\right) \\
  &amp;\leq \frac{1}{1-{\left \vert \left \vert A^{-1}\Delta A \right \vert \right \vert}} \left( {\left \vert \left \vert x \right \vert \right \vert} + \frac{r}{\epsilon {\left \vert \left \vert A \right \vert \right \vert}} \cdot {\left \vert \left \vert \Delta b \right \vert \right \vert} \right) \\
  &amp;\leq \frac{1}{1-r} \left( {\left \vert \left \vert x \right \vert \right \vert} + \frac{r}{\epsilon {\left \vert \left \vert A \right \vert \right \vert}} \cdot \epsilon {\left \vert \left \vert b \right \vert \right \vert} \right) \\
  &amp;= \frac{1}{1-r} \left( {\left \vert \left \vert x \right \vert \right \vert} + \frac{r \cdot {\left \vert \left \vert b \right \vert \right \vert}}{{\left \vert \left \vert A \right \vert \right \vert}} \right).
\end{aligned}
\]</span></p>
<p>Finally, recall that <span class="math inline">\(Ax=b\)</span>, hence <span class="math inline">\({\left \vert \left \vert A \right \vert \right \vert}\cdot{\left \vert \left \vert x \right \vert \right \vert} \geq {\left \vert \left \vert b \right \vert \right \vert}\)</span>, so <span class="math inline">\({\left \vert \left \vert x \right \vert \right \vert} \geq \frac{{\left \vert \left \vert b \right \vert \right \vert}}{{\left \vert \left \vert A \right \vert \right \vert}}\)</span>. So,</p>
<p><span class="math display">\[
\begin{aligned}
  {\left \vert \left \vert y \right \vert \right \vert} \leq \frac{1}{1-r}  \left( {\left \vert \left \vert x \right \vert \right \vert} + r \cdot {\left \vert \left \vert x \right \vert \right \vert} \right) \Leftrightarrow \\
  \frac{{\left \vert \left \vert y \right \vert \right \vert}}{{\left \vert \left \vert x \right \vert \right \vert}} \leq \frac{1+r}{1-r}.
\end{aligned}
\]</span></p>
</div>


<div class="lemma">
<span id="lem:unnamed-chunk-17" class="lemma"><strong>Lemma 3.7  </strong></span><span class="math display">\[\frac{{\left \vert \left \vert y - x \right \vert \right \vert}}{{\left \vert \left \vert x \right \vert \right \vert}} \leq \frac{2\epsilon {\left \vert \left \vert A^{-1} \right \vert \right \vert}\cdot {\left \vert \left \vert A \right \vert \right \vert}}{1-r}.\]</span>
</div>


<div class="proof">
<p> <span class="proof"><em>Proof. </em></span>  <span class="math display">\[
\begin{aligned}
  \left(A+\Delta A\right)y &amp;= b + \Delta b \Leftrightarrow \\
  Ay - b &amp;= \Delta b - \Delta Ay \Leftrightarrow \\
  y - A^{-1}b &amp;= A^{-1} \Delta b - A^{-1}\Delta A y \Leftrightarrow \\
  y - x &amp;= A^{-1} \Delta b - A^{-1}\Delta A y \Leftrightarrow \\
  {\left \vert \left \vert y - x \right \vert \right \vert} &amp;\leq {\left \vert \left \vert A^{-1} \right \vert \right \vert} {\left \vert \left \vert \Delta b \right \vert \right \vert} + {\left \vert \left \vert A^{-1} \right \vert \right \vert} {\left \vert \left \vert \Delta A \right \vert \right \vert}{\left \vert \left \vert y \right \vert \right \vert} \\   &amp;\leq {\left \vert \left \vert A^{-1} \right \vert \right \vert} \epsilon {\left \vert \left \vert b \right \vert \right \vert} + {\left \vert \left \vert A^{-1} \right \vert \right \vert} \epsilon{\left \vert \left \vert A \right \vert \right \vert}{\left \vert \left \vert y \right \vert \right \vert} \\   &amp;\leq \epsilon {\left \vert \left \vert A^{-1} \right \vert \right \vert} {\left \vert \left \vert A \right \vert \right \vert}{\left \vert \left \vert x \right \vert \right \vert} + \epsilon{\left \vert \left \vert A^{-1} \right \vert \right \vert}{\left \vert \left \vert A \right \vert \right \vert}{\left \vert \left \vert y \right \vert \right \vert} \\   &amp;\leq \epsilon {\left \vert \left \vert A^{-1} \right \vert \right \vert} {\left \vert \left \vert A \right \vert \right \vert}\left({\left \vert \left \vert x \right \vert \right \vert} + {\left \vert \left \vert y \right \vert \right \vert}\right) \\
  &amp;= \epsilon {\left \vert \left \vert A^{-1} \right \vert \right \vert} {\left \vert \left \vert A \right \vert \right \vert}\left({\left \vert \left \vert x \right \vert \right \vert} + \frac{1+r}{1-r}{\left \vert \left \vert x \right \vert \right \vert}\right) \Leftrightarrow \\
\frac{{\left \vert \left \vert y-x \right \vert \right \vert}}{{\left \vert \left \vert x \right \vert \right \vert}} &amp;\leq \epsilon {\left \vert \left \vert A^{-1} \right \vert \right \vert} {\left \vert \left \vert A \right \vert \right \vert} \left(\frac{1-r}{1-r} + \frac{1+r}{1-r}\right) \\
  &amp;= 2\epsilon {\left \vert \left \vert A^{-1} \right \vert \right \vert} {\left \vert \left \vert A \right \vert \right \vert} \frac{1}{1-r}
\end{aligned}
\]</span></p>
</div>

</div>
</div>
<div id="orthogonalization" class="section level2">
<h2><span class="header-section-number">3.2</span> Orthogonalization</h2>
<p>Goals</p>
<ol style="list-style-type: decimal">
<li>Introduce and prove the existence of QR decomposition</li>
<li>Overview of the algorithm to perfor QR decomposition</li>
<li>Solve least squares problems</li>
<li>“Large” data problems</li>
</ol>
<p>Outline</p>
<ol style="list-style-type: decimal">
<li>Motivating problems and solutions with QR</li>
<li>Gram-Schmidt procedure, existence of QR</li>
<li>Householder, Givens</li>
<li>“Large” least squares problems datadown</li>
</ol>
<div id="motivating-problems" class="section level3">
<h3><span class="header-section-number">3.2.1</span> Motivating problems</h3>

<div class="example">
<span id="exm:linear-system" class="example"><strong>Example 3.1  (Motivating Problem 1 (Consistent Linear System))  </strong></span>Assume <span class="math inline">\(A \in {\mathbb{R}}^{n\times m}, n \geq m, \text{rank}(A) = m\)</span>, and <span class="math inline">\(b \in \text{range}(A) \subset R^m\)</span>. Find <span class="math inline">\(x \in {\mathbb{R}}^m\)</span> s.t. <span class="math inline">\(Ax = b\)</span>.
</div>


<div class="example">
<span id="exm:least-squares" class="example"><strong>Example 3.2  (Motivating Problem 2 (Least Squares Regression))  </strong></span>Assume <span class="math inline">\(A \in {\mathbb{R}}^{n\times m}, n \geq m, \text{rank}(A) = m\)</span>, and <span class="math inline">\(b \in R^n\)</span>. Find <span class="math inline">\(x \in {\mathbb{R}}^m\)</span> s.t. <span class="math display">\[x \in {\text{argmin}}_{y \in {\mathbb{R}}^m} {\left \vert \left \vert Ay-b \right \vert \right \vert}_2.\]</span>
</div>


<div class="example">
<p><span id="exm:und-linear-system" class="example"><strong>Example 3.3  (Motivating Problem 3 (Underdetermined Linear System)  </strong></span>Assume <span class="math inline">\(A \in {\mathbb{R}}^{n\times m}, n \geq m, \text{rank}(A) &lt; m\)</span>, and <span class="math inline">\(b \in \text{range}(A)\)</span>. Find <span class="math inline">\(x \in {\mathbb{R}}^m\)</span> s.t.</p>
<span class="math display">\[x \in {\text{argmin}}_{y \in {\mathbb{R}}^m} \left\{ {\left \vert \left \vert y \right \vert \right \vert}_2 \left | Ay = b \right\} \right . .\]</span>
</div>


<div class="example">
<p><span id="exm:und-least-squares" class="example"><strong>Example 3.4  (Motivating Problem 4 (Underdetermined Least Squares Regression))  </strong></span>Assume <span class="math inline">\(A \in {\mathbb{R}}^{n\times m}, n \geq m, \text{rank}(A) &lt; m\)</span>, and <span class="math inline">\(b \in {\mathbb{R}}^n\)</span>. Find <span class="math inline">\(x \in {\mathbb{R}}^m\)</span> s.t.</p>
<span class="math display">\[x \in {\text{argmin}}_{z \in {\mathbb{R}}^m} \left\{ {\left \vert \left \vert z \right \vert \right \vert}_2 \left | {\left \vert \left \vert Ay - b \right \vert \right \vert}_2 = \min_{y \in {\mathbb{R}}^m} {\left \vert \left \vert Ay-b \right \vert \right \vert}_2 \right\} \right . .\]</span>
</div>


<div class="example">
<p><span id="exm:constrained-least-squares" class="example"><strong>Example 3.5  (Motivating Problem 5 (Constrained Least Squares Regression))  </strong></span>Assume <span class="math inline">\(A \in {\mathbb{R}}^{n\times m}, n \geq m, \text{rank}(A) &lt; m\)</span>, and <span class="math inline">\(b \in {\mathbb{R}}^n\)</span>. Let <span class="math inline">\(C \in {\mathbb{R}}^{p\times m}, \text{C} = p\)</span>, and <span class="math inline">\(d \in {\mathbb{R}}^{p}\)</span>. Find <span class="math inline">\(x \in {\mathbb{R}}^m\)</span> s.t.</p>
<span class="math display">\[x = {\text{argmin}}_{y \in {\mathbb{R}}^m} {\left \vert \left \vert Ay - b \right \vert \right \vert}_2\quad \text{s.t.} \quad Cy = d.\]</span>
</div>

<p>Before we take a crack at solving these problems, we will need to get some definitions down.</p>

<div class="definition">
<span id="def:perm-matrix" class="definition"><strong>Definition 3.2  (Permutation Matrix)  </strong></span>A permutation matrix is a square matrix such that each column has exactly one element that is <span class="math inline">\(1\)</span>, the rest are <span class="math inline">\(0\)</span>.
</div>


<div class="example">
<p><span id="exm:unnamed-chunk-19" class="example"><strong>Example 3.6  </strong></span>The following is a permutation matrix:</p>
<span class="math display">\[
  \begin{bmatrix}
    0 &amp; 1 \\
    1 &amp; 0
  \end{bmatrix}
\]</span>
</div>


<div class="definition">
<span id="def:unnamed-chunk-20" class="definition"><strong>Definition 3.3  (Orthogonal Matrix)  </strong></span>A matrix <span class="math inline">\(Q\)</span> is said to be an <em>orthogonal matrix</em> if <span class="math inline">\(Q^T Q = Q Q^T = I\)</span>.
</div>

<p>Note: for an orthogonal matrix <span class="math inline">\(Q \in {\mathbb{R}}^{n\times m}\)</span>, it holds that <span class="math inline">\({\left \vert \left \vert Q_{i*} \right \vert \right \vert}_2 = 1\)</span> for all <span class="math inline">\(i=1,\ldots,n\)</span>, and <span class="math inline">\({\left \vert \left \vert Q_{*j} \right \vert \right \vert}_2 = 1\)</span> for all <span class="math inline">\(j = 1,\ldots, m\)</span>.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></p>

<div class="definition">
<span id="def:unnamed-chunk-21" class="definition"><strong>Definition 3.4  (Upper Triangular Matrix)  </strong></span>A matrix <span class="math inline">\(R\)</span> is an <em>upper triangular matrix</em> if <span class="math inline">\(R_{ij} = 0\)</span> for all <span class="math inline">\(i&gt;j\)</span>.
</div>

</div>
</div>
<div id="lecture-4-918" class="section level2">
<h2><span class="header-section-number">3.3</span> Lecture 4: 9/18</h2>
<div id="qr-decomposition" class="section level3">
<h3><span class="header-section-number">3.3.1</span> QR Decomposition</h3>
<p>In order to actually solve the problems listed above, we need the QR Decomposition:</p>

<div class="theorem">
<p><span id="thm:qr-decomposition" class="theorem"><strong>Theorem 3.2  (Existence of QR Decomposition)  </strong></span>Let <span class="math inline">\(A \in {\mathbb{R}}^{n \times m}\)</span> and let <span class="math inline">\(r = rank(A)\)</span>. Then there exists:</p>
<ol style="list-style-type: decimal">
<li>an <span class="math inline">\(m\times m\)</span> permutation matrix <span class="math inline">\(\Pi\)</span>,</li>
<li>an <span class="math inline">\(n \times n\)</span> orthogonal matrix <span class="math inline">\(Q\)</span>,</li>
<li>an <span class="math inline">\(r \times r\)</span> upper triangular matrix <span class="math inline">\(R\)</span>, with non-zero diagonal elements (i.e. invertible)</li>
<li>an <span class="math inline">\(r \times (m-r)\)</span> matrix S (if <span class="math inline">\(m &gt; r\)</span>),</li>
</ol>
<p>such that</p>
<span class="math display">\[
  A = Q \begin{bmatrix} R &amp; S \\ 0 &amp; 0 \end{bmatrix} \Pi^T.
\]</span><br />

</div>

<p>With this in hand, we can solve the motivating problems stated above.</p>

<div class="solution">
<p> <span class="solution"><em>Solution</em> (Example <a href="part-lecture-2-911.html#exm:linear-system">3.1</a>). </span>  We want to find <span class="math inline">\(x\)</span> such that <span class="math inline">\(Ax = b\)</span>.</p>
<p>We use theorem <a href="part-lecture-2-911.html#thm:qr-decomposition">3.2</a> to rewrite this as <span class="math inline">\(Q \begin{bmatrix} R \\ 0 \end{bmatrix} \Pi^T x = b\)</span>. Note that since <span class="math inline">\(\text{rank}(A) = m\)</span>, there is no <span class="math inline">\(S\)</span> matrix.</p>
<p>Now, since <span class="math inline">\(Q\)</span> is an orthogonal matrix, we know that <span class="math inline">\(Q^{-1} = Q^T\)</span>, so</p>
<span class="math display" id="eq:sol-linear-system">\[\begin{equation}
  \begin{bmatrix} R \\ 0 \end{bmatrix} \Pi^T x = Q^T b = c = \begin{bmatrix} c_1 \\ 0 \end{bmatrix}. \tag{3.1}
\end{equation}\]</span>
<p>So now the equation we are trying to solve becomes</p>
<p><span class="math display">\[
  R \Pi^T x = c_1.
\]</span></p>
<p>Since <span class="math inline">\(R\)</span> is an upper triangular matrix with non-zero diagonal elements, it is invertible. Since <span class="math inline">\(\Pi\)</span> is a permutation matrix, <span class="math inline">\(\Pi^{-1} = \Pi^T\)</span>. Using this we can find the solution:</p>
<p><span class="math display">\[
  x = \Pi R^{-1} c_1.
\]</span></p>
</div>


<div class="solution">
<p> <span class="solution"><em>Solution</em> (Example @(exm:least-squares). </span> We want to find <span class="math inline">\(x\)</span> such that <span class="math inline">\(x \in {\text{argmin}}_{y \in {\mathbb{R}}^m}{\left \vert \left \vert Ay-b \right \vert \right \vert}_2\)</span>.</p>
<p>Once again, <span class="math inline">\(\text{rank}(A) = m\)</span>, so using theorem <a href="part-lecture-2-911.html#thm:qr-decomposition">3.2</a>, we can rewrite the expression we are trying to minimize as</p>
<p><span class="math display" id="eq:least-squares-eq1">\[
  \min {\left \vert \left \vert Q \begin{bmatrix} R \\ 0 \end{bmatrix}\Pi^T y - b \right \vert \right \vert}_2. \tag{3.2}
\]</span></p>
<p>Since <span class="math inline">\(Q^T = Q^{-1}\)</span> is orthogonal, <span class="math inline">\({\left \vert \left \vert Q^T x \right \vert \right \vert}_2 = {\left \vert \left \vert x \right \vert \right \vert}_2\)</span> for all <span class="math inline">\(x\)</span> (homework exercise <a href="homework-assignments.html#exr:q402">4.28</a>). So, we get that <a href="part-lecture-2-911.html#eq:least-squares-eq1">(3.2)</a> is the same as</p>
<p><span class="math display">\[
  \min{\left \vert \left \vert \begin{bmatrix} R \\ 0 \end{bmatrix} \Pi^T y - Q^T b \right \vert \right \vert}_2.
\]</span></p>
<p>Now let <span class="math inline">\(c = Q^T b\)</span>. Then, <span class="math inline">\(c\)</span> is of the form <span class="math inline">\(\begin{bmatrix} c_1 \\ c_2 \end{bmatrix}\)</span>, where <span class="math inline">\(c_2\)</span> is the last <span class="math inline">\(n-r\)</span> rows (i.e. corresponding to the <span class="math inline">\(0\)</span> rows of <span class="math inline">\(\begin{bmatrix} R \\ 0 \end{bmatrix}\)</span>). Then</p>
<p><span class="math display">\[
  \min{\left \vert \left \vert \begin{bmatrix} R \Pi^T y - c_1 \\ -c_2 \end{bmatrix} \right \vert \right \vert}_2 = \min \sqrt{{\left \vert \left \vert R \Pi^T y - c_1 \right \vert \right \vert}_2^2 + {\left \vert \left \vert c_2 \right \vert \right \vert}_2^2}.
\]</span></p>
<p>Now this is minimized by <span class="math inline">\({\text{argmin}}_y {\left \vert \left \vert R \Pi^T y - c_1 \right \vert \right \vert}_2^2\)</span>. As before, <span class="math inline">\(R^{-1}\)</span> exists since <span class="math inline">\(R\)</span> is upper triangular with non-zero diagonal elements, <span class="math inline">\(\Pi^T = \Pi^{-1}\)</span> since <span class="math inline">\(\Pi\)</span> is a permutation matrix, so</p>
<span class="math display">\[
  \begin{aligned}
    x &amp;= {\text{argmin}}_y {\left \vert \left \vert R \Pi^T y - c_1 \right \vert \right \vert}_2^2 \Leftrightarrow \\
    R \Pi^T x &amp;= c_1 \Leftrightarrow \\
    x &amp;= \Pi R^{-1} c_1.
  \end{aligned}
\]</span>
</div>


<div class="solution">
<p> <span class="solution"><em>Solution</em> (Example <a href="part-lecture-2-911.html#exm:und-linear-system">3.3</a>). </span>  In this scenario, <span class="math inline">\(\text{rank}(A) = r &lt; m\)</span>. We are looking for <span class="math inline">\(x \in {\text{argmin}}_{y}\left\{{\left \vert \left \vert y \right \vert \right \vert}_2 \left | Ay = b\right\}\right .\)</span>. Using theorem <a href="part-lecture-2-911.html#thm:qr-decomposition">3.2</a>, we can rewrite this as <span class="math inline">\({\text{argmin}}_y\left\{{\left \vert \left \vert y \right \vert \right \vert}_2 | Q\begin{bmatrix} R &amp; S \\ 0 &amp; 0 \end{bmatrix} y = b \right\}\)</span>, and multiplying by <span class="math inline">\(Q^T\)</span>, <span class="math inline">\({\text{argmin}}_y\left\{{\left \vert \left \vert y \right \vert \right \vert}_2 \left | \begin{bmatrix} R &amp; S \\ 0 &amp; 0 \end{bmatrix} y = Q^T b \right\} \right .\)</span>. We introduce the vector <span class="math inline">\(c\)</span> such that <span class="math inline">\(Q^T b = \begin{bmatrix} c &amp; 0 \end{bmatrix}^T\)</span> (<span class="math inline">\(0\)</span> entries correspond to <span class="math inline">\(0\)</span> rows in <span class="math inline">\(\begin{bmatrix} R &amp; S \\ 0 &amp; 0 \end{bmatrix}\)</span>). If we furthermore write <span class="math inline">\(\Pi^T y\)</span> as <span class="math inline">\(\begin{bmatrix} z_1 &amp; z_2 \end{bmatrix}^T\)</span>.</p>
<p>Then, since <span class="math inline">\({\left \vert \left \vert y \right \vert \right \vert}_2 = {\left \vert \left \vert z \right \vert \right \vert}_2\)</span>, our problem becomes</p>
<p><span class="math display">\[
  \begin{aligned}
    x &amp;\in {\text{argmin}}_z \left\{{\left \vert \left \vert z \right \vert \right \vert}_2 \left | R z_1 + S z_2 = c \right\}\right. \\
    x &amp;\in {\text{argmin}}_z \left\{{\left \vert \left \vert z \right \vert \right \vert}_2 \left | z_1 = R^{-1} c - R^{-1} S z_2 \right\}\right. \\
    x &amp;\in {\text{argmin}}_z \sqrt{{\left \vert \left \vert R^{-1}c - R^{-1} S z_2 \right \vert \right \vert}_2^2 + {\left \vert \left \vert z_2 \right \vert \right \vert}_2^2} \\
    x &amp;\in {\text{argmin}}_z \left\{{\left \vert \left \vert R^{-1}c - R^{-1} S z_2 \right \vert \right \vert}_2^2 + {\left \vert \left \vert z_2 \right \vert \right \vert}_2^2\right\},
  \end{aligned}
\]</span></p>
<p>where the last equality is a consequence of the result proved in homework @ref{exr:q403}. Now, let <span class="math inline">\(d = R^{-1}c\)</span> and <span class="math inline">\(p = R^{-1}Sz_2\)</span>. Then we can find the minimum of the above expression by differentiating and setting equal to zero:</p>
<span class="math display">\[\begin{align}
  0 &amp;= -P^Td + (P^TP + I)z_2 \rightarrow
  z_2 &amp;= (P^T P + I)^{-1}P^Td.
\end{align}\]</span>
</div>


<div class="solution">
<p> <span class="solution"><em>Solution</em> (Example <a href="part-lecture-2-911.html#exm:und-least-squares">3.4</a>). </span>  We want to find <span class="math inline">\(\min_z \left\{ {\left \vert \left \vert z \right \vert \right \vert}_2 \left \vert z \in {\text{argmin}}_y {\left \vert \left \vert Ay - b \right \vert \right \vert}_2\right\} \right .\)</span> Use theorem <a href="part-lecture-2-911.html#thm:qr-decomposition">3.2</a>:</p>
<p><span class="math display">\[\begin{aligned}
  \min_z \left\{ {\left \vert \left \vert z \right \vert \right \vert}_2 \left \vert z \in {\text{argmin}}_y {\left \vert \left \vert Ay - b \right \vert \right \vert}_2\right\} \right . &amp;= \left\{ {\left \vert \left \vert z \right \vert \right \vert}_2 \left \vert z \in {\text{argmin}}_y {\left \vert \left \vert \begin{bmatrix} R &amp; S \\ 0 &amp; 0 \end{bmatrix} \Pi^T y - Q^T b \right \vert \right \vert}_2\right\} \right . \\
  &amp;= \left\{ {\left \vert \left \vert w \right \vert \right \vert}_2 \left \vert w \in {\text{argmin}}_y {\left \vert \left \vert \begin{bmatrix} R &amp; S \\ 0 &amp; 0 \end{bmatrix}  y - Q^T b \right \vert \right \vert}_2\right\} \right .,
\end{aligned}\]</span></p>
<p>since <span class="math inline">\({\left \vert \left \vert y \right \vert \right \vert}_2 = {\left \vert \left \vert \Pi^T y \right \vert \right \vert}_2\)</span>. This is exactly the problem solved in example <a href="part-lecture-2-911.html#exm:und-linear-system">3.3</a>. In conclusion,</p>
<p><span class="math display">\[
  w = \begin{bmatrix} R^{-1}(c_1 - Sy_y) \\ y_2 \end{bmatrix}.
\]</span></p>
</div>


<div class="solution">
 <span class="solution"><em>Solution</em> (Example <a href="part-lecture-2-911.html#exm:constrained-least-squares">3.5</a>. </span> 
</div>

</div>
<div id="existence-of-qr-decomposition." class="section level3">
<h3><span class="header-section-number">3.3.2</span> Existence of QR-decomposition.</h3>
<p>To prove the existence of the QR-decomposition, we need the Gram-Schmidt process.</p>

<div class="lemma">
<p><span id="lem:gsp" class="lemma"><strong>Lemma 3.8  (The Gram-Schmidt Process)  </strong></span>Let <span class="math inline">\(r \in {\mathbb{N}}\)</span>. Given a set of linearly independent vectors <span class="math inline">\(\{a_1, \ldots, a_r\}\)</span>, there exists a set of orthonormal vectors <span class="math inline">\(\{q_1, \ldots, q_r\}\)</span> such that <span class="math inline">\(\text{span} \{q_1, \ldots, q_r\} = \text{span}\{a_1, \ldots, a_r\}\)</span>.</p>
<p>The <span class="math inline">\(q_i\)</span>’s are given by…</p>
</div>


<div class="proof">
<p> <span class="proof"><em>Proof. </em></span> We will prove this by induction. For <span class="math inline">\(i=1\)</span>: let <span class="math inline">\(R_{11} = {\left \vert \left \vert a_1 \right \vert \right \vert}_2\)</span>, <span class="math inline">\(q_1 = \frac{1}{R_11}a_1\)</span>. Notice that <span class="math inline">\({\left \vert \left \vert q_1 \right \vert \right \vert} = 1\)</span>.</p>
<p>(At this point, it might be beneficial to check out the intuitive side note (<a href="part-lecture-2-911.html#cnj:gram-schmidt-remark">3.1</a>))</p>
<p>Define <span class="math inline">\(q^r\)</span> in the following way: let <span class="math inline">\(R_{ir} = q_i^\prime a_r\)</span>, <span class="math inline">\(\tilde{q}_r = a_r - \sum_{i=1}^{r-1} R_{ir}q_i\)</span>, and <span class="math inline">\(R_rr = {\left \vert \left \vert \tilde{q}_r \right \vert \right \vert}_2\)</span>. Then <span class="math inline">\(q_r = \frac{\tilde{q}_r}{R_{rr}}\)</span>. (Note: <span class="math inline">\(\tilde{q}_r \neq 0\)</span> since the <span class="math inline">\(a_i\)</span>s are linearly independent, and <span class="math inline">\(q_i\)</span> is given as a linear combination of <span class="math inline">\(a_1, \ldots, a_i\)</span>.)</p>
<p>Assume the result holds for <span class="math inline">\(i \le r-1\)</span>. I.e. we have vectors <span class="math inline">\(q_1, \ldots, q_{r-1}\)</span> given as above, and that</p>
<ol style="list-style-type: lower-roman">
<li><span class="math inline">\(\text{span}\{q_1, \ldots, q_{r-1}\} = \text{span}\{a_1, \ldots, a_{r-1}\}\)</span>,</li>
<li><span class="math inline">\(q_i \cdot q_j\)</span> for all <span class="math inline">\(i,j = 1, \ldots, r-1\)</span> with <span class="math inline">\(i \neq j\)</span>,</li>
<li><span class="math inline">\(q_i^\prime \cdot q_i = 1\)</span> for all <span class="math inline">\(i = 1, \ldots, r-1\)</span>.</li>
</ol>
<p>Now, we want to show that we can construct a <span class="math inline">\(q_r\)</span> such that</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(\text{span}\{q_1, \ldots, q_r\} = \text{span}\{a_1, \ldots, a_r\}\)</span>,</li>
<li><span class="math inline">\(q_r \cdot q_j = 0\)</span> for all <span class="math inline">\(j = 1, \ldots, r-1\)</span>,</li>
<li><span class="math inline">\(q_r^\prime \cdot q_r = 1\)</span>.</li>
</ol>
<p>We start from below.</p>
<ol start="3" style="list-style-type: lower-alpha">
<li>By definition of <span class="math inline">\(q_r\)</span>: <span class="math inline">\(q_r^\prime q_r = \frac{\tilde{q}_r^\prime \tilde{q}_r}{R_{rr}^2} = \frac{{\left \vert \left \vert \tilde{q}_r \right \vert \right \vert}^2}{R_{rr}^2} = 1\)</span>.</li>
<li>Let <span class="math inline">\(i &lt; r\)</span>. Then</li>
</ol>
<p><span class="math display">\[\begin{aligned}
  q_i^{\prime} \tilde{q}_r &amp;= q_i^\prime a_r - \sum_{j=1}^{r-1} R_{jr} q_i^\prime q_j \\
                           &amp;= q_i^\prime a_r - R_{ir} q_i^\prime q_i \\
                           &amp;= q_i^\prime a_r - R_{ir} = 0 \text{ (by definition of } R_{ir}\text{)}.
\end{aligned}\]</span></p>
<ol style="list-style-type: lower-alpha">
<li>We need to show that <span class="math inline">\(a_r\)</span> can be written as a linear combination of <span class="math inline">\(q_i\)</span>s.</li>
</ol>
<span class="math display">\[\begin{aligned}
  \sum_{i=1}^r R_{ir} q_i &amp;= \sum_{i=1}^{r-1} R_{ir} q_i + R_{rr} q_r \\
                          &amp;= \sum_{i=1}^{r-1} R_{ir} q_i + R_{rr} \frac{1}{R_{rr}} \tilde{q}_r \\
                          &amp;= \sum_{i=1}^{r-1} R_{ir} q_i + R_{rr} \frac{1}{R_{rr}} \left(a_r - \sum_{i=1}^{r-1} R_{ir}q_i \right) \\
                          &amp;= \sum_{i=1}^{r-1} R_{ir} q_i + a_r - \sum_{i=1}^{r-1} R_{ir}q_i \\
                          &amp;= a_r.
\end{aligned}\]</span>
</div>


<div class="conjecture">
<p><span id="cnj:gram-schmidt-remark" class="conjecture"><strong>Remark 3.1  (Intuitive side note)  </strong></span>It is fairly easy to find <span class="math inline">\(q_2\)</span>. We want to find it such that <span class="math inline">\(a_2 = R_{12}q_1 + R_{22} q_2\)</span>, and <span class="math inline">\({\left \vert \left \vert q_2 \right \vert \right \vert}_2 = 1\)</span> and <span class="math inline">\(q_1 \perp q_2\)</span>, i.e. <span class="math inline">\(q_1 \cdot q_2 = 0\)</span>. So, if we multiply the equation by <span class="math inline">\(q_1\)</span>, we get that <span class="math inline">\(q_1 a_2 = R_{12}\)</span>. Substituting this into the first equation, <span class="math inline">\(q_2 = \frac{a_2 - R_{12} q_1}{R_{22}}\)</span>.</p>
Note that this is a circular argument, and hence not a formal way of doing this.
</div>

</div>
</div>
<div id="lecture-5-920" class="section level2">
<h2><span class="header-section-number">3.4</span> Lecture 5: 9/20</h2>
<p>(Finished up proof of The Gram-Schmidt Process (<a href="part-lecture-2-911.html#lem:gsp">3.8</a>))</p>

<div class="conjecture">
<p><span id="cnj:unnamed-chunk-28" class="conjecture"><strong>Remark 3.2  (Gram-Schmidt in Matrix Form)  </strong></span>If we write up <span class="math inline">\(a_1, \ldots, a_r\)</span> in a matrix, we see that</p>
<p><span class="math display">\[
  \begin{bmatrix} 
    a_1 &amp; \dots &amp; a_r 
  \end{bmatrix} = 
      \begin{bmatrix}
        q_1 &amp; \dots &amp; q_r
      \end{bmatrix} 
        \begin{bmatrix}
          R_{11} &amp; R_{12} &amp; \dots &amp; R_{1r} \\
          0      &amp; R_{22} &amp; \dots &amp; R_{2r} \\
          \vdots &amp; \ddots &amp; \ddots &amp;  \vdots \\
          0 &amp; \ldots &amp; 0 &amp; R_{rr}
        \end{bmatrix}
\]</span></p>
This is quite similar to the result we are after (the QR-decomposition <a href="part-lecture-2-911.html#thm:qr-decomposition">3.2</a>).
</div>


<div class="proof">
<p> <span class="proof"><em>Proof</em> (Proof of theorem <a href="part-lecture-2-911.html#thm:qr-decomposition">3.2</a>). </span> Since <span class="math inline">\(\text{rank}(A) = r\)</span>, <span class="math inline">\(A\)</span> has <span class="math inline">\(r\)</span> linearly independent columns. Hence, there exists a permutation matrix <span class="math inline">\(\Pi\)</span> such that</p>
<p><span class="math display">\[
  A \Pi = \begin{bmatrix} a_1 &amp; \dots &amp; a_r &amp; a_{r+1} \dots a_m \end{bmatrix},
\]</span></p>
<p>where <span class="math inline">\(a_1, \ldots, a_r\)</span> are linearly independent, and <span class="math inline">\(a_{r+1}, \ldots, a_m\)</span> are linearly dependent on the first <span class="math inline">\(r\)</span> columns.</p>
<p>Using Gram-Schmidt (lemma <a href="part-lecture-2-911.html#lem:gsp">3.8</a>), we know that there exists <span class="math inline">\(\tilde{Q} \in {\mathbb{R}}^{n \times r}, R \in {\mathbb{R}}^{r \times r}\)</span> such that <span class="math inline">\(A\Pi = \tilde{Q} R\)</span>. Since <span class="math inline">\(\text{span}\{\tilde{q}_1, \ldots, \tilde{q}_r\}\)</span> (columns of <span class="math inline">\(\tilde{Q}\)</span>) is equal to <span class="math inline">\(\text{span}\{a_1, \ldots, a_r\}\)</span>, there exists an <span class="math inline">\(s_{k(j-r+2)}\)</span> for any <span class="math inline">\(j \in \{r+1, \ldots, m\}\)</span> and <span class="math inline">\(k \in \{1, \ldots, r\}\)</span> such that <span class="math inline">\(a_j = \sum_{k=1}^r s_{k(j-r+2)}q_k\)</span>. So,</p>
<p><span class="math display">\[
  A\Pi = \tilde{Q} \begin{bmatrix} R &amp; S \end{bmatrix}.
\]</span></p>
<p>This is almost the form we want, BUT <span class="math inline">\(\tilde{Q}\)</span> is not orthonormal (it is not square). However, we know that we can pick <span class="math inline">\(n-r\)</span> vectors from <span class="math inline">\({\mathbb{R}}^n\)</span> such that adding these as columns to <span class="math inline">\(\tilde{Q}\)</span> we get a set of <span class="math inline">\(n\)</span> linearly independent columns. Now, use Gram-Schmidt to normalize. Since the first <span class="math inline">\(r\)</span> columns are already normalized, these will stay the same. The result is a matrix <span class="math inline">\(Q\)</span>, where the columns are all length <span class="math inline">\(1\)</span>, and they are all linearly independent. I.e. <span class="math inline">\(Q^TQ = I\)</span>. So, <span class="math inline">\(A\Pi = Q \begin{bmatrix} R &amp; S \\ 0 &amp; 0 \end{bmatrix}\)</span>, hence</p>
<p><span class="math display">\[
  A = Q \begin{bmatrix} R &amp; S \\ 0 &amp; 0 \end{bmatrix} \Pi^T.
\]</span></p>
</div>

<p>Basically, this gives us a way to perform QR decomposition. However, using the Gram-Schmidt procedure is NOT numerical stable. I.e. we might end up with matrices <span class="math inline">\(Q, R\)</span>, and <span class="math inline">\(S\)</span> from which we CANNOT recover <span class="math inline">\(A\)</span>. To overcome this, there is a different method called the <em>Modified Gram-Schmidt Procedure</em>.</p>

<div class="lemma">
<span id="lem:mod-gsp" class="lemma"><strong>Lemma 3.9  (The Modified Gram-Schmidt Procedure)  </strong></span><strong>HOMEWORK</strong>
</div>

<div id="householder" class="section level3">
<h3><span class="header-section-number">3.4.1</span> Householder</h3>

<div class="definition">
<span id="def:unnamed-chunk-30" class="definition"><strong>Definition 3.5  (Householder Reflections)  </strong></span>A matrix <span class="math inline">\(H = I - 2vv^\prime\)</span>, where <span class="math inline">\({\left \vert \left \vert v \right \vert \right \vert}_2 = 1\)</span>, is called a <em>Householder Reflection</em>.
</div>

<p>A Householder reflection takes any vector and reflects it over <span class="math inline">\(\{tv: t \in {\mathbb{R}}\}\)</span>.</p>

<div class="lemma">
<span id="lem:unnamed-chunk-31" class="lemma"><strong>Lemma 3.10  </strong></span>Householder reflections are orthogonal matrices.
</div>


<div class="proof">
 <span class="proof"><em>Proof. </em></span> <em>HOMEWORK</em>
</div>


<div class="lemma">
<span id="lem:unnamed-chunk-33" class="lemma"><strong>Lemma 3.11  </strong></span>There exists Householder refelctions <span class="math inline">\(H_1, \ldots, H_r\)</span> such that <span class="math inline">\(H_r \dots H_1 A\Pi = R\)</span>.
</div>


<div class="proof">
<p> <span class="proof"><em>Proof. </em></span> Let <span class="math inline">\(A\Pi = \begin{bmatrix} a_1 \dots a_r \end{bmatrix}\)</span>. Choose <span class="math inline">\(H_1\)</span> s.t. <span class="math inline">\(H_1 a_1 = R_{11} e_1 = a_1 - 2v_1v_1^\prime a_1\)</span> (last equality due to definition of Householder reflections). This is equivalent to <span class="math inline">\(v_1(2v_1^\prime a_1) = a_1 - R_{11}e_1\)</span>.</p>
<p>Now, let <span class="math inline">\(v_1 = \frac{a_1 - R_{11}e_1}{{\left \vert \left \vert a_1 - R_{11}e_2 \right \vert \right \vert}_2}\)</span>. Plug this into the equation for <span class="math inline">\(R_{11}e_1\)</span> above to get</p>
<p><span class="math display">\[
  R_{11}e_1 = a_1 - \frac{(a_1 - R_{11}e_1)}{{\left \vert \left \vert a_1 - R_{11}e_1 \right \vert \right \vert}_2}\frac{a_1^\prime a_1 - R_{11} a_1^\prime e_1}{{\left \vert \left \vert a_1 - R_{11}e_1 \right \vert \right \vert}_2}.
\]</span></p>
<p>If we multiply this by <span class="math inline">\(e_1^\prime\)</span> from the right, we get</p>
<p><span class="math display">\[
  R_{11} = \pm {\left \vert \left \vert a_1 \right \vert \right \vert}_2, v_1 = \frac{a_1 - {\left \vert \left \vert a_1 \right \vert \right \vert}e_1}{{\left \vert \left \vert a_1 - {\left \vert \left \vert a_1 \right \vert \right \vert}_2 e_1 \right \vert \right \vert}_2}.
\]</span></p>
<span class="math display">\[ 
  H_1 = I - \frac{a_1 - {\left \vert \left \vert a_1 \right \vert \right \vert}_2e_1)(a_1 - {\left \vert \left \vert a_1 \right \vert \right \vert}_2 e_1)}{{\left \vert \left \vert a_1 - {\left \vert \left \vert a_1 \right \vert \right \vert}_2 e_1 \right \vert \right \vert}_2^2}
\]</span>
</div>

</div>
<div id="givens-rotations" class="section level3">
<h3><span class="header-section-number">3.4.2</span> Givens Rotations</h3>

<div class="definition">
<p><span id="def:givens" class="definition"><strong>Definition 3.6  (Givens Rotations)  </strong></span>A <em>Givens Rotation</em> is a matrix <span class="math inline">\(G^{(i,j)}\)</span> with entries <span class="math inline">\((g_{ij})\)</span> such that</p>
<ol style="list-style-type: lower-roman">
<li><span class="math inline">\(g_{ii} = g_{jj} = \lambda\)</span> (the <span class="math inline">\(i\)</span>th and <span class="math inline">\(j\)</span>th elements of the diagonal are <span class="math inline">\(\lambda\)</span>).</li>
<li><span class="math inline">\(g_{kk} = 1\)</span> for all <span class="math inline">\(k \notin \{i,j\}\)</span>. (all other diagonal elements are <span class="math inline">\(1\)</span>)</li>
<li><span class="math inline">\(g_{ij} = g_{ji} = \sigma\)</span></li>
<li><span class="math inline">\(g_{ij} = 0\)</span> for all other pairs of <span class="math inline">\(i,j\)</span>.</li>
</ol>
<p>In words: <span class="math inline">\(G^{(i,j)}\)</span> is the identity matrix with the <span class="math inline">\(i\)</span>th and <span class="math inline">\(j\)</span>th diagonal elements made <span class="math inline">\(\lambda\)</span>, and the entries at <span class="math inline">\((i,j)\)</span> and <span class="math inline">\((j,i)\)</span> are <span class="math inline">\(\sigma\)</span>.</p>
</div>


</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>Here we use the notion <span class="math inline">\(Q_{i*}\)</span> to mean the <span class="math inline">\(i\)</span>’th row, and <span class="math inline">\(Q_{*j}\)</span> to mean the <span class="math inline">\(j\)</span>’th column of <span class="math inline">\(Q\)</span>.<a href="part-lecture-2-911.html#fnref1">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="lecture-notes.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="homework-assignments.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
},
"toolbar": {
"position": "fixed"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
